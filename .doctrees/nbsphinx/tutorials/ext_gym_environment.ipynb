{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9097e1f3",
   "metadata": {},
   "source": [
    "# Gym Environment Interface: minimal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9101b6db-e9c2-4f29-bc50-de5d3231f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ry version: 0.1.7 compile time: Feb 13 2024 12:22:55\n"
     ]
    }
   ],
   "source": [
    "import robotic as ry\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "print('ry version:', ry.__version__, ry.compiled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f641c445-4901-4d95-9ecd-c931d6b80bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A basic configuration, where the orange box is to be pushed to the target with the stick\n",
    "\n",
    "C = ry.Config()\n",
    "C.addFile(ry.raiPath('scenarios/pandaSingle.g'))\n",
    "C.view(False)\n",
    "\n",
    "C.addFrame('box') \\\n",
    "    .setShape(ry.ST.ssBox, size=[.1,.1,.1,.005]) .setColor([1,.5,0]) \\\n",
    "    .setPosition([.1,.35,.9]) \\\n",
    "    .setMass(.1)\n",
    "\n",
    "C.addFrame('stick', 'l_gripper') \\\n",
    "    .setShape(ry.ST.capsule, size=[.3,.02]) .setColor([.5,1,0]) \\\n",
    "    .setRelativePosition([0,0,-.13])\n",
    "\n",
    "C.addFrame('target') \\\n",
    "    .setShape(ry.ST.marker, size=[.1]) .setColor([0,1,0]) \\\n",
    "    .setPosition([.5,.0,.7]) \\\n",
    "\n",
    "C.setJointState([.0], ['l_panda_joint2']) #only cosmetics\n",
    "C.setJointState([.02], ['l_panda_finger_joint1']) #only cosmetics\n",
    "\n",
    "q0 = C.getJointState()\n",
    "X0 = C.getFrameState()\n",
    "\n",
    "C.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e95379-5ff6-4b05-abaf-f356550653b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic gym environment, instantiating pyhsx multibody sim, with velocity control\n",
    "# the arguments C, time_limit, and reward_fct define the problem\n",
    "\n",
    "class RaiGym(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "    tau = .05\n",
    "    time = 0.\n",
    "\n",
    "    def __init__(self, C, time_limit, reward_fct, render_mode=None):\n",
    "        self.C = C\n",
    "        self.time_limit = time_limit\n",
    "        self.reward_fct = reward_fct\n",
    "        self.render_mode = render_mode\n",
    "        #self.limits = self.C.getJointLimits()\n",
    "        self.limits = [-10., 10.]\n",
    "        self.q0 = self.C.getJointState()\n",
    "        self.X0 = self.C.getFrameState()\n",
    "\n",
    "        self.observation_space = gym.spaces.box.Box(self.limits[0], self.limits[1], shape=(self.q0.size,), dtype=np.float32)\n",
    "        self.action_space = gym.spaces.box.Box(low=-1., high=1., shape=(self.q0.size,), dtype=np.float32)\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.sim = ry.Simulation(self.C, ry.SimulationEngine.physx, 0)\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.sim\n",
    "        del self.C\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.sim.step(action, self.tau, ry.ControlMode.velocity)\n",
    "        self.time += self.tau\n",
    "        \n",
    "        observation = self.C.getJointState()\n",
    "        reward = self.reward_fct(C)\n",
    "        terminated = (self.time >= self.time_limit)\n",
    "        info = {\"no\": \"additional info\"}\n",
    "\n",
    "        return observation, reward, terminated, False, info\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.time = 0.\n",
    "        self.sim.setState(X0, q0)\n",
    "        self.sim.resetSplineRef()\n",
    "\n",
    "        observation = self.C.getJointState()\n",
    "        info = {\"no\": \"additional info\"}\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.C.view(False)\n",
    "\n",
    "        return observation, info\n",
    "        \n",
    "    def render(self):\n",
    "        self.C.view(False, f'RaiGym time {self.time} / {self.time_limit}')\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self.C.view_getRgb()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c78b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward function\n",
    "\n",
    "def reward_function(C):\n",
    "    touch, _ = C.eval(ry.FS.negDistance, [\"stick\", \"box\"])\n",
    "    dist, _ = C.eval(ry.FS.positionDiff, [\"box\", \"target\"])\n",
    "    r = touch[0] - np.linalg.norm(dist)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58f2904-b563-440a-8be8-20226544afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = RaiGym(C, 10., reward_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e99cf13a-44d5-4c5b-8e75-f0b5e3868f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  0.  0.  0.  0.  0.  0.]\n",
      "reward:  -0.5893210723155677\n",
      "reward:  -0.5747704604290415\n",
      "reward:  -0.5607111276733189\n",
      "reward:  -0.5630630200485639\n",
      "reward:  -0.5524492814971189\n",
      "reward:  -0.5490595054403244\n",
      "reward:  -0.5450311473737579\n",
      "reward:  -0.5405927227372814\n",
      "reward:  -0.5357799838867628\n",
      "reward:  -0.5307265738687247\n",
      "reward:  -0.5266044574494736\n",
      "reward:  -0.5220843731557211\n",
      "reward:  -0.5187751552671973\n",
      "reward:  -0.5146539024644406\n",
      "reward:  -0.5106346294164319\n",
      "reward:  -0.5069171041641415\n",
      "reward:  -0.5028811562461459\n",
      "reward:  -0.49920249292239577\n",
      "reward:  -0.4956529159405116\n",
      "reward:  -0.4919866111875385\n",
      "reward:  -0.4882585681405122\n",
      "reward:  -0.4846028546796664\n",
      "reward:  -0.48103014149541995\n",
      "reward:  -0.47766487000996394\n",
      "reward:  -0.4744564425913193\n",
      "reward:  -0.47114841059972473\n",
      "reward:  -0.4680937740787613\n",
      "reward:  -0.4647754586856758\n",
      "reward:  -0.4618417588663975\n",
      "reward:  -0.45899672438976946\n",
      "reward:  -0.45594942627170015\n",
      "reward:  -0.4533128286247184\n",
      "reward:  -0.4504513890345941\n",
      "reward:  -0.44803077414417725\n",
      "reward:  -0.44545723650816366\n",
      "reward:  -0.4428230801139267\n",
      "reward:  -0.4407920199957383\n",
      "reward:  -0.43843060489651625\n",
      "reward:  -0.4368303664507525\n",
      "reward:  -0.4352362759610853\n",
      "reward:  -0.4338769210743494\n",
      "reward:  -0.4327823772118763\n",
      "reward:  -0.43168981254902467\n",
      "reward:  -0.430875033453886\n",
      "reward:  -0.4299212448553999\n",
      "reward:  -0.42925657609175427\n",
      "reward:  -0.4286154185812337\n",
      "reward:  -0.4287812015812647\n",
      "reward:  -0.42896932480567124\n",
      "reward:  -0.42918343092758454\n",
      "reward:  -0.42916086799965597\n",
      "reward:  -0.43011985473384484\n",
      "reward:  -0.43107937095281057\n",
      "reward:  -0.4317696953696482\n",
      "reward:  -0.4319738691185515\n",
      "reward:  -0.43226692826803487\n",
      "reward:  -0.4330985327941867\n",
      "reward:  -0.4335369430447368\n",
      "reward:  -0.4367391430991906\n",
      "reward:  -0.44140956029581147\n",
      "reward:  -0.44686835695949706\n",
      "reward:  -0.45306295955331083\n",
      "reward:  -0.4596463757299924\n",
      "reward:  -0.4666368131324597\n",
      "reward:  -0.4738164751679942\n",
      "reward:  -0.48127378210703975\n",
      "reward:  -0.48886077073068596\n",
      "reward:  -0.4965639203763162\n",
      "reward:  -0.504441642613094\n",
      "reward:  -0.5123355874640078\n",
      "reward:  -0.5203980614342415\n",
      "reward:  -0.5284513804382757\n",
      "reward:  -0.5366440910688468\n",
      "reward:  -0.5448156256772849\n",
      "reward:  -0.5531075674626571\n",
      "reward:  -0.5614026965651391\n",
      "reward:  -0.5697322439507883\n",
      "reward:  -0.578091205840531\n",
      "reward:  -0.5864751846111518\n",
      "reward:  -0.5948801184436218\n",
      "reward:  -0.6033024065126582\n",
      "reward:  -0.6117387968573689\n",
      "reward:  -0.6201862630566651\n",
      "reward:  -0.6286421252642512\n",
      "reward:  -0.637103778348565\n",
      "reward:  -0.645569036641159\n",
      "reward:  -0.6540357692939806\n",
      "reward:  -0.6625019454948967\n",
      "reward:  -0.6709657502640319\n",
      "reward:  -0.6794255424340554\n",
      "reward:  -0.687879667853498\n",
      "reward:  -0.6963267131716873\n",
      "reward:  -0.7047651812304079\n",
      "reward:  -0.7131939231919392\n",
      "reward:  -0.7216116134810627\n",
      "reward:  -0.7300170860243367\n",
      "reward:  -0.7384092951028979\n",
      "reward:  -0.7467871675773672\n",
      "reward:  -0.7551496828334537\n",
      "reward:  -0.7634959084484187\n",
      "reward:  -0.7718250031087277\n",
      "reward:  -0.7801359714559364\n",
      "reward:  -0.7884281014918246\n",
      "reward:  -0.7967004980249931\n",
      "reward:  -0.8049523998129055\n",
      "reward:  -0.81318311374539\n",
      "reward:  -0.82139176644358\n",
      "reward:  -0.8295778051278829\n",
      "reward:  -0.8377405137055951\n",
      "reward:  -0.8458791444046063\n",
      "reward:  -0.853993095763835\n",
      "reward:  -0.8620817089221808\n",
      "reward:  -0.8701443905530937\n",
      "reward:  -0.8781804949649956\n",
      "reward:  -0.8861894963110732\n",
      "reward:  -0.8941706952239443\n",
      "reward:  -0.9021236959472269\n",
      "reward:  -0.9100477482981317\n",
      "reward:  -0.9179424054163361\n",
      "reward:  -0.925807097688286\n",
      "reward:  -0.9336411463165584\n",
      "reward:  -0.941444232728776\n",
      "reward:  -0.9492156240132523\n",
      "reward:  -0.9569549463248468\n",
      "reward:  -0.9646615932702021\n",
      "reward:  -0.9723350794326755\n",
      "reward:  -0.9799749197027867\n",
      "reward:  -0.987580576778655\n",
      "reward:  -0.9951516292025429\n",
      "reward:  -1.002687546037211\n",
      "reward:  -1.0101877411490991\n",
      "reward:  -1.0176519152306092\n",
      "reward:  -1.0250794302574704\n",
      "reward:  -1.03246993780835\n",
      "reward:  -1.0398228056387062\n",
      "reward:  -1.0471377444517411\n",
      "reward:  -1.054414188305309\n",
      "reward:  -1.0616516284885873\n",
      "reward:  -1.0688497792776028\n",
      "reward:  -1.0760080294633056\n",
      "reward:  -1.0831259881448314\n",
      "reward:  -1.090203160574529\n",
      "reward:  -1.0972392690785\n",
      "reward:  -1.1042337144502024\n",
      "reward:  -1.1111860650220733\n",
      "reward:  -1.1180958895997348\n",
      "reward:  -1.1249628128576088\n",
      "reward:  -1.1317864091665448\n",
      "reward:  -1.1385662043970444\n",
      "reward:  -1.1453017794363698\n",
      "reward:  -1.1519927166845205\n",
      "reward:  -1.1586386023403061\n",
      "reward:  -1.165239078421762\n",
      "reward:  -1.17179368399821\n",
      "reward:  -1.1783020139440357\n",
      "reward:  -1.184763667423819\n",
      "reward:  -1.1911782449773702\n",
      "reward:  -1.1975453508782599\n",
      "reward:  -1.2038645911420165\n",
      "reward:  -1.2101355759575672\n",
      "reward:  -1.216357919138294\n",
      "reward:  -1.2225312350008484\n",
      "reward:  -1.2286551428185273\n",
      "reward:  -1.2347292645193504\n",
      "reward:  -1.2407532257861045\n",
      "reward:  -1.2467266548610505\n",
      "reward:  -1.2526491838907485\n",
      "reward:  -1.2585204449963512\n",
      "reward:  -1.2643400774207825\n",
      "reward:  -1.2701077218913681\n",
      "reward:  -1.275823023045167\n",
      "reward:  -1.2814856274423236\n",
      "reward:  -1.287095185507769\n",
      "reward:  -1.2926513508814168\n",
      "reward:  -1.2981537805029626\n",
      "reward:  -1.3036021891556775\n",
      "reward:  -1.3089961876171226\n",
      "reward:  -1.314335441993705\n",
      "reward:  -1.319619624596823\n",
      "reward:  -1.3248484087747416\n",
      "reward:  -1.3300214709843445\n",
      "reward:  -1.3351384922049994\n",
      "reward:  -1.3401991565087548\n",
      "reward:  -1.3452031514790777\n",
      "reward:  -1.350150167925937\n",
      "reward:  -1.3550399010990561\n",
      "reward:  -1.3598720484715254\n",
      "reward:  -1.3646463121915073\n",
      "reward:  -1.369362397635541\n",
      "reward:  -1.3740200121651611\n",
      "reward:  -1.3786188697237012\n",
      "reward:  -1.3831586843359456\n",
      "reward:  -1.3876391769237826\n",
      "reward:  -1.3920600700245105\n",
      "reward:  -1.3964210909419024\n",
      "reward:  -1.400721970317837\n",
      "reward:  -1.4049624424743636\n",
      "reward:  -1.4091422443182493\n",
      "reward:  -1.4132611175566308\n"
     ]
    }
   ],
   "source": [
    "# basic test\n",
    "\n",
    "g.reset()\n",
    "v = np.zeros(g.q0.size)\n",
    "v[0] = -1.\n",
    "print(v)\n",
    "t = 0\n",
    "while True:\n",
    "    t += 1\n",
    "    ret = g.step(v)\n",
    "    if ret[2]:\n",
    "        break;\n",
    "    print(\"reward: \", ret[1])\n",
    "    if not (t%10):\n",
    "        g.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee831fc-436f-461f-9644-4ad6a6516094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a stable baslines\n",
    "\n",
    "from stable_baselines3 import A2C, SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17cc305e-5c9f-4798-b4e8-be5f890c54a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = SAC(\"MlpPolicy\", g, verbose=1)\n",
    "#model = A2C(\"MlpPolicy\", g, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd665ada-a480-4e9a-a3c2-aab5dba20761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -117     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 68       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 800      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.7    |\n",
      "|    critic_loss     | 0.127    |\n",
      "|    ent_coef        | 0.811    |\n",
      "|    ent_coef_loss   | -2.47    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 699      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7f577b7b60a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a06410a-0941-48f2-851c-3d6143e3060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the policy\n",
    "\n",
    "obs, info = g.reset()\n",
    "for t in range(100):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    ret = g.step(action)\n",
    "    if not (t%10):\n",
    "        g.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fcd5153-e8a3-4612-b314-914cf19cb455",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del g\n",
    "del C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c020be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
