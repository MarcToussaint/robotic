{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9097e1f3",
   "metadata": {},
   "source": [
    "# Gym Environment Interface: minimal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9101b6db-e9c2-4f29-bc50-de5d3231f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ry version: 0.1.8 compile time: Feb 26 2024 21:50:27\n"
     ]
    }
   ],
   "source": [
    "import robotic as ry\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "print('ry version:', ry.__version__, ry.compiled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f641c445-4901-4d95-9ecd-c931d6b80bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A basic configuration, where the orange box is to be pushed to the target with the stick\n",
    "\n",
    "C = ry.Config()\n",
    "C.addFile(ry.raiPath('scenarios/pandaSingle.g'))\n",
    "C.view(False)\n",
    "\n",
    "C.addFrame('box') \\\n",
    "    .setShape(ry.ST.ssBox, size=[.1,.1,.1,.005]) .setColor([1,.5,0]) \\\n",
    "    .setPosition([.1,.35,.9]) \\\n",
    "    .setMass(.1)\n",
    "\n",
    "C.addFrame('stick', 'l_gripper') \\\n",
    "    .setShape(ry.ST.capsule, size=[.3,.02]) .setColor([.5,1,0]) \\\n",
    "    .setRelativePosition([0,0,-.13])\n",
    "\n",
    "C.addFrame('target') \\\n",
    "    .setShape(ry.ST.marker, size=[.1]) .setColor([0,1,0]) \\\n",
    "    .setPosition([.5,.0,.7]) \\\n",
    "\n",
    "C.setJointState([.0], ['l_panda_joint2']) #only cosmetics\n",
    "C.setJointState([.02], ['l_panda_finger_joint1']) #only cosmetics\n",
    "\n",
    "q0 = C.getJointState()\n",
    "X0 = C.getFrameState()\n",
    "\n",
    "C.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e95379-5ff6-4b05-abaf-f356550653b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic gym environment, instantiating pyhsx multibody sim, with velocity control\n",
    "# the arguments C, time_limit, and reward_fct define the problem\n",
    "\n",
    "class RaiGym(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "    tau = .05\n",
    "    time = 0.\n",
    "\n",
    "    def __init__(self, C, time_limit, reward_fct, render_mode=None):\n",
    "        self.C = C\n",
    "        self.time_limit = time_limit\n",
    "        self.reward_fct = reward_fct\n",
    "        self.render_mode = render_mode\n",
    "        #self.limits = self.C.getJointLimits()\n",
    "        self.limits = [-10., 10.]\n",
    "        self.q0 = self.C.getJointState()\n",
    "        self.X0 = self.C.getFrameState()\n",
    "\n",
    "        self.observation_space = gym.spaces.box.Box(self.limits[0], self.limits[1], shape=(self.q0.size,), dtype=np.float32)\n",
    "        self.action_space = gym.spaces.box.Box(low=-1., high=1., shape=(self.q0.size,), dtype=np.float32)\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.sim = ry.Simulation(self.C, ry.SimulationEngine.physx, 0)\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.sim\n",
    "        del self.C\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.sim.step(action, self.tau, ry.ControlMode.velocity)\n",
    "        self.time += self.tau\n",
    "        \n",
    "        observation = self.C.getJointState()\n",
    "        reward = self.reward_fct(C)\n",
    "        terminated = (self.time >= self.time_limit)\n",
    "        info = {\"no\": \"additional info\"}\n",
    "\n",
    "        return observation, reward, terminated, False, info\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.time = 0.\n",
    "        self.sim.setState(X0, q0)\n",
    "        self.sim.resetSplineRef()\n",
    "\n",
    "        observation = self.C.getJointState()\n",
    "        info = {\"no\": \"additional info\"}\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.C.view(False)\n",
    "\n",
    "        return observation, info\n",
    "        \n",
    "    def render(self):\n",
    "        self.C.view(False, f'RaiGym time {self.time} / {self.time_limit}')\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self.C.view_getRgb()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c78b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward function\n",
    "\n",
    "def reward_function(C):\n",
    "    touch, _ = C.eval(ry.FS.negDistance, [\"stick\", \"box\"])\n",
    "    dist, _ = C.eval(ry.FS.positionDiff, [\"box\", \"target\"])\n",
    "    r = touch[0] - np.linalg.norm(dist)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58f2904-b563-440a-8be8-20226544afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = RaiGym(C, 10., reward_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e99cf13a-44d5-4c5b-8e75-f0b5e3868f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  0.  0.  0.  0.  0.  0.]\n",
      "reward:  -0.5893210723155677\n",
      "reward:  -0.5747704604085424\n",
      "reward:  -0.5607111282717746\n",
      "reward:  -0.5630630193037823\n",
      "reward:  -0.5526126975096675\n",
      "reward:  -0.548855507884232\n",
      "reward:  -0.5446356504735119\n",
      "reward:  -0.5404041677106877\n",
      "reward:  -0.5355761968416785\n",
      "reward:  -0.5305064150295323\n",
      "reward:  -0.5267102253488318\n",
      "reward:  -0.5231001385229148\n",
      "reward:  -0.5190994993102397\n",
      "reward:  -0.5151942664330835\n",
      "reward:  -0.5114000324234872\n",
      "reward:  -0.5077107457070799\n",
      "reward:  -0.5039480055221426\n",
      "reward:  -0.500171503736764\n",
      "reward:  -0.4965198458938494\n",
      "reward:  -0.4928791268707496\n",
      "reward:  -0.4891557324962862\n",
      "reward:  -0.48569171365156044\n",
      "reward:  -0.48201554188095325\n",
      "reward:  -0.4784995808185587\n",
      "reward:  -0.4748108202282276\n",
      "reward:  -0.47096072050656135\n",
      "reward:  -0.46749700895847557\n",
      "reward:  -0.4638239898787941\n",
      "reward:  -0.46013569618786765\n",
      "reward:  -0.4567251093731977\n",
      "reward:  -0.4532226717560402\n",
      "reward:  -0.449598309751659\n",
      "reward:  -0.4464303200193492\n",
      "reward:  -0.44308481320924054\n",
      "reward:  -0.4399751287346834\n",
      "reward:  -0.4371890256934602\n",
      "reward:  -0.43434511183220065\n",
      "reward:  -0.43137160580864303\n",
      "reward:  -0.42860779315592806\n",
      "reward:  -0.4258293253849189\n",
      "reward:  -0.42335558968492376\n",
      "reward:  -0.42086511717527997\n",
      "reward:  -0.418522944107307\n",
      "reward:  -0.41636697606257167\n",
      "reward:  -0.4142598802659565\n",
      "reward:  -0.41238064099726096\n",
      "reward:  -0.41020517236690673\n",
      "reward:  -0.40828858151446545\n",
      "reward:  -0.40673621975521684\n",
      "reward:  -0.405164053854981\n",
      "reward:  -0.4037779261049056\n",
      "reward:  -0.40242369523666155\n",
      "reward:  -0.4016517857664458\n",
      "reward:  -0.4015413875962686\n",
      "reward:  -0.40129557865124754\n",
      "reward:  -0.40118173333515583\n",
      "reward:  -0.4010202664832648\n",
      "reward:  -0.40095505382980134\n",
      "reward:  -0.4010015398892874\n",
      "reward:  -0.4008974615732725\n",
      "reward:  -0.40106267552966307\n",
      "reward:  -0.40103246515576896\n",
      "reward:  -0.4015886539622809\n",
      "reward:  -0.4032511576922282\n",
      "reward:  -0.4077921796005921\n",
      "reward:  -0.41299387910850205\n",
      "reward:  -0.4191877807141245\n",
      "reward:  -0.42576005177460646\n",
      "reward:  -0.43276787007401546\n",
      "reward:  -0.4400379972632281\n",
      "reward:  -0.4475101406190001\n",
      "reward:  -0.45515682266346713\n",
      "reward:  -0.46282972117174553\n",
      "reward:  -0.47083384513809834\n",
      "reward:  -0.47877825709980093\n",
      "reward:  -0.4868465974425138\n",
      "reward:  -0.4949862797878318\n",
      "reward:  -0.5031662553561733\n",
      "reward:  -0.5114133613281165\n",
      "reward:  -0.5196858143832078\n",
      "reward:  -0.5280024413160056\n",
      "reward:  -0.5363497931962409\n",
      "reward:  -0.5447231813278781\n",
      "reward:  -0.5531184060616432\n",
      "reward:  -0.5615317224665407\n",
      "reward:  -0.5699597564177313\n",
      "reward:  -0.5783994611480141\n",
      "reward:  -0.5868480580924167\n",
      "reward:  -0.5953030718585272\n",
      "reward:  -0.6037621803435829\n",
      "reward:  -0.6122231468821935\n",
      "reward:  -0.6206841447542182\n",
      "reward:  -0.6291432409726093\n",
      "reward:  -0.6375987424483144\n",
      "reward:  -0.6460491333137139\n",
      "reward:  -0.6544928691524952\n",
      "reward:  -0.6629286906232716\n",
      "reward:  -0.6713551309467258\n",
      "reward:  -0.6797711486365773\n",
      "reward:  -0.6881754857480546\n",
      "reward:  -0.6965670950090641\n",
      "reward:  -0.7049448320418115\n",
      "reward:  -0.7133078590985156\n",
      "reward:  -0.7216551708118797\n",
      "reward:  -0.729985835615865\n",
      "reward:  -0.7382989970934896\n",
      "reward:  -0.7465938118996639\n",
      "reward:  -0.7548695472093165\n",
      "reward:  -0.7631253322971197\n",
      "reward:  -0.7713604742909825\n",
      "reward:  -0.7795742831740153\n",
      "reward:  -0.7877659513164386\n",
      "reward:  -0.7959348653835823\n",
      "reward:  -0.8040803550255031\n",
      "reward:  -0.8122018122687449\n",
      "reward:  -0.8202985181484461\n",
      "reward:  -0.8283699397385871\n",
      "reward:  -0.8364153621195924\n",
      "reward:  -0.8444342642219178\n",
      "reward:  -0.8524260022802395\n",
      "reward:  -0.8603900586392084\n",
      "reward:  -0.8683259218525221\n",
      "reward:  -0.8762329585697572\n",
      "reward:  -0.8841105438685797\n",
      "reward:  -0.8919581739040783\n",
      "reward:  -0.8997754096076145\n",
      "reward:  -0.9075616349675306\n",
      "reward:  -0.9153163556740791\n",
      "reward:  -0.92303902227836\n",
      "reward:  -0.9307291473640815\n",
      "reward:  -0.9383862455039891\n",
      "reward:  -0.9460097770594569\n",
      "reward:  -0.9535992600768224\n",
      "reward:  -0.9611541637786898\n",
      "reward:  -0.9686740708935149\n",
      "reward:  -0.9761584537963235\n",
      "reward:  -0.9836068444292498\n",
      "reward:  -0.991018720133978\n",
      "reward:  -0.9983937311917892\n",
      "reward:  -1.0057312489438117\n",
      "reward:  -1.01303092720307\n",
      "reward:  -1.020292312142317\n",
      "reward:  -1.0275148428281384\n",
      "reward:  -1.0346981217869653\n",
      "reward:  -1.0418417579624755\n",
      "reward:  -1.0489452539386745\n",
      "reward:  -1.0560081132626464\n",
      "reward:  -1.0630299009962663\n",
      "reward:  -1.0700101808956937\n",
      "reward:  -1.07694857292398\n",
      "reward:  -1.083844645375629\n",
      "reward:  -1.090697973147377\n",
      "reward:  -1.0975080777011113\n",
      "reward:  -1.104274538038407\n",
      "reward:  -1.1109969867701601\n",
      "reward:  -1.1176748543822987\n",
      "reward:  -1.124307832122699\n",
      "reward:  -1.1308955099524445\n",
      "reward:  -1.1374374805467453\n",
      "reward:  -1.1439333387731918\n",
      "reward:  -1.1503827812161098\n",
      "reward:  -1.1567853125769507\n",
      "reward:  -1.1631405357951003\n",
      "reward:  -1.169448059137383\n",
      "reward:  -1.1757074905771518\n",
      "reward:  -1.181918447072912\n",
      "reward:  -1.188080543325488\n",
      "reward:  -1.1941933986398843\n",
      "reward:  -1.2002566352442343\n",
      "reward:  -1.2062698801263851\n",
      "reward:  -1.2122327619616402\n",
      "reward:  -1.2181449117008323\n",
      "reward:  -1.224005965986352\n",
      "reward:  -1.2298155617358948\n",
      "reward:  -1.2355732534755721\n",
      "reward:  -1.2412787746029557\n",
      "reward:  -1.2469317745127797\n",
      "reward:  -1.252531901394343\n",
      "reward:  -1.2580788110556977\n",
      "reward:  -1.2635721606019192\n",
      "reward:  -1.2690116113733814\n",
      "reward:  -1.2743968288393686\n",
      "reward:  -1.2797274793582667\n",
      "reward:  -1.285003233691842\n",
      "reward:  -1.2902237661548306\n",
      "reward:  -1.2953887559000243\n",
      "reward:  -1.300497882370356\n",
      "reward:  -1.3055508311756228\n",
      "reward:  -1.3105472898549462\n",
      "reward:  -1.3154869502109416\n",
      "reward:  -1.32036950698841\n",
      "reward:  -1.3251946597103306\n",
      "reward:  -1.3299621097469219\n",
      "reward:  -1.334671562044423\n",
      "reward:  -1.3393227266838663\n",
      "reward:  -1.3439153147284304\n",
      "reward:  -1.3484490439591295\n",
      "reward:  -1.3529236338575064\n",
      "reward:  -1.3573388087643419\n"
     ]
    }
   ],
   "source": [
    "# basic test\n",
    "\n",
    "g.reset()\n",
    "v = np.zeros(g.q0.size)\n",
    "v[0] = -1.\n",
    "print(v)\n",
    "t = 0\n",
    "while True:\n",
    "    t += 1\n",
    "    ret = g.step(v)\n",
    "    if ret[2]:\n",
    "        break;\n",
    "    print(\"reward: \", ret[1])\n",
    "    if not (t%10):\n",
    "        g.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee831fc-436f-461f-9644-4ad6a6516094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a stable baslines\n",
    "\n",
    "from stable_baselines3 import A2C, SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17cc305e-5c9f-4798-b4e8-be5f890c54a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = SAC(\"MlpPolicy\", g, verbose=1)\n",
    "#model = A2C(\"MlpPolicy\", g, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd665ada-a480-4e9a-a3c2-aab5dba20761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -122     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 800      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.6    |\n",
      "|    critic_loss     | 0.669    |\n",
      "|    ent_coef        | 0.811    |\n",
      "|    ent_coef_loss   | -2.46    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 699      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7f82f6eaf0a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a06410a-0941-48f2-851c-3d6143e3060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the policy\n",
    "\n",
    "obs, info = g.reset()\n",
    "for t in range(100):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    ret = g.step(action)\n",
    "    if not (t%10):\n",
    "        g.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fcd5153-e8a3-4612-b314-914cf19cb455",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del g\n",
    "del C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c020be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
