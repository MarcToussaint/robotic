<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Rendering: Basic opengl, offscreen (headless), and interface to physics-based rendering &mdash; Robotic Python Library 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=01f34227"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="RRT: basic finding example" href="ext_rrt.html" />
    <link rel="prev" title="Simulation: Low-level stepping interface &amp; gym environments" href="ext_physx_simulation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Robotic Python Library
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="config_1_intro.html">Intro: Configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="botop_1_intro.html">Intro: BotOp (Robot Operation) interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="komo_1_intro.html">Intro: KOMO - Motion Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="botop_2_real_robot.html">Real robot operation: Checklist &amp; first steps</a></li>
<li class="toctree-l2"><a class="reference internal" href="config_2_features.html">Features: Computing differentiable features &amp; collision evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="config_3_import_edit.html">Configurations: Importing, editing &amp; manipulating them</a></li>
<li class="toctree-l2"><a class="reference internal" href="config_3_import_edit.html#Creating-a-grid-of-duplicated-configurations">Creating a grid of duplicated configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="komo_2_reporting.html">KOMO: Reporting &amp; explaining convergence</a></li>
<li class="toctree-l2"><a class="reference internal" href="komo_3_manipulation.html">Manipulation Modelling &amp; Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="ext_physx_simulation.html">Simulation: Low-level stepping interface &amp; gym environments</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Rendering: Basic opengl, offscreen (headless), and interface to physics-based rendering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Grabbing-images-and-depth-from-the-view-window">Grabbing images and depth from the view window</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Saving-pngs-for-video-generation">Saving pngs for video generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Offscreen-(headless)-CameraView">Offscreen (headless) CameraView</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Point-Cloud">Point Cloud</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Physics-based-Rendering-using-Nvidia-NVISII">Physics-based Rendering using Nvidia NVISII</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ext_rrt.html">RRT: basic finding example</a></li>
<li class="toctree-l2"><a class="reference internal" href="ext_nlp_solvers.html">NLP interface: Low-level NLP formulation and solving</a></li>
<li class="toctree-l2"><a class="reference internal" href="ext_gym_environment.html">Gym Environment Interface: minimal example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../script/script.html">Lecture Script</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">robotic python API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Robotic Python Library</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../tutorials.html">Tutorials</a></li>
      <li class="breadcrumb-item active">Rendering: Basic opengl, offscreen (headless), and interface to physics-based rendering</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorials/ext_rendering.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Rendering:-Basic-opengl,-offscreen-(headless),-and-interface-to-physics-based-rendering">
<h1>Rendering: Basic opengl, offscreen (headless), and interface to physics-based rendering<a class="headerlink" href="#Rendering:-Basic-opengl,-offscreen-(headless),-and-interface-to-physics-based-rendering" title="Link to this heading"></a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">view</span></code> is realized using very basic OpenGL rendering. It is straight-forward to grab the image (and, e.g., make a video from such images), as well as the depth (e.g. to simulate a depth camera).</p>
<p>However, grabbing from the actual view window is brittle, as it depends on the window manager and might give weird results if the window is not visible. The package provides an offscreen (headless) implementation of the OpenGL rendering, which allows to compute images and depth (also object segmentation labels) without window or X.</p>
<p>The simple OpenGL rendering is ok for depth camera simulation, but not visually realistic. An interface to Nvidia’s NVISSI physics-based rendering enables very flexible realistic rendering.</p>
<section id="Grabbing-images-and-depth-from-the-view-window">
<h2>Grabbing images and depth from the view window<a class="headerlink" href="#Grabbing-images-and-depth-from-the-view-window" title="Link to this heading"></a></h2>
<p>The view is internally implemented using glfw and most basic opengl. It’s simple to grab the rgb and depth buffers.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import robotic as ry
import numpy as np
import matplotlib.pyplot as plt
print(ry.__version__, ry.compiled())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>C = ry.Config()
C.addFile(ry.raiPath(&#39;scenarios/pandaSingle.g&#39;))
C.view()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rgb = C.view_getRgb()
depth = C.view_getDepth()
print(rgb.shape, depth.shape)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig = plt.figure()
fig.add_subplot(1,2,1)
plt.imshow(rgb)
fig.add_subplot(1,2,2)
plt.imshow(depth)
plt.show()
</pre></div>
</div>
</div>
<p>The camera pose can be set to be at a particular frame. (Create a dedicated frame, if you want freedom to set the camera). Also camera intrinsics (focalLength, width, height) can be set with frame attributes. Our scene has a <code class="docutils literal notranslate"><span class="pre">cameraTop</span></code> predefined:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>f = C.getFrame(&#39;cameraTop&#39;)
f.setAttribute(&#39;focalLength&#39;, .5) # wide angle
f.setAttribute(&#39;width&#39;, 500)
f.setAttribute(&#39;height&#39;, 500)
C.view_setCamera(f)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>C.view_setCamera(None)
</pre></div>
</div>
</div>
</section>
<section id="Saving-pngs-for-video-generation">
<h2>Saving pngs for video generation<a class="headerlink" href="#Saving-pngs-for-video-generation" title="Link to this heading"></a></h2>
<p>There might be many better ways to generate a video. But a simple one it to write many numered pngs and call ffmpeg on shell. For instance:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># first ensure a folder
import os
os.system(&#39;mkdir -p z.vid&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>q = C.getJointState()

for t in range(30):
    q = q + .02
    C.setJointState(q)
    C.view()
    C.view_savePng(&#39;z.vid/&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>os.system(&#39;ffmpeg -v 16 -f image2 -framerate 12 -i z.vid/%04d.png -c:v libx264 -r 25 -pix_fmt yuv420p -y vid.mp4&#39;)
</pre></div>
</div>
</div>
<p>…which creates an mp4 with 12 images per second.</p>
</section>
<section id="Offscreen-(headless)-CameraView">
<h2>Offscreen (headless) CameraView<a class="headerlink" href="#Offscreen-(headless)-CameraView" title="Link to this heading"></a></h2>
<p>But this way of grabbing images and depth from the view window is brittle (as it depends on the window manager) and also includes markers and non-visual objects. A much better way is to use offscreen method:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cam = ry.CameraView(C)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rgb, depth = cam.computeImageAndDepth(C)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig = plt.figure()
fig.add_subplot(1,2,1)
plt.imshow(rgb)
fig.add_subplot(1,2,2)
plt.imshow(depth)
plt.show()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cam.setCamera(&#39;cameraTop&#39;) # cameraWrist is another pre-defined frame
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rgb, depth = cam.computeImageAndDepth(C)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig = plt.figure()
fig.add_subplot(1,2,1)
plt.imshow(rgb)
fig.add_subplot(1,2,2)
plt.imshow(depth)
plt.show()
</pre></div>
</div>
</div>
</section>
<section id="Point-Cloud">
<h2>Point Cloud<a class="headerlink" href="#Point-Cloud" title="Link to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import robotic as ry
import matplotlib.pyplot as plt
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>C = ry.Config()
C.addFile(ry.raiPath(&#39;scenarios/pandaSingle.g&#39;))
C.view()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cam = ry.CameraView(C)
cam.setCamera(&#39;cameraTop&#39;)
rgb, depth = cam.computeImageAndDepth(C)
pcl = ry.depthImage2PointCloud(depth, cam.getFxycxy())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(rgb.shape, depth.shape, pcl.shape)
print(C.view_fxycxy())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig = plt.figure()
fig.add_subplot(1,2,1)
plt.imshow(rgb)
fig.add_subplot(1,2,2)
plt.imshow(depth)
plt.show()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>f = C.addFrame(&#39;pcl&#39;, &#39;cameraTop&#39;)
f.setPointCloud(pcl, [255,0,0])
C.view()
</pre></div>
</div>
</div>
</section>
<section id="Physics-based-Rendering-using-Nvidia-NVISII">
<h2>Physics-based Rendering using Nvidia NVISII<a class="headerlink" href="#Physics-based-Rendering-using-Nvidia-NVISII" title="Link to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import robotic as ry
from matplotlib import pyplot as plt
from robotic import render
print(&#39;version&#39;, ry.compiled())
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>C = ry.Config()
C.addFile(ry.raiPath(&#39;scenarios/pandaSingle.g&#39;))
C.view()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>C.addFrame(&#39;light1&#39;) .setPosition([1,0,2]) .setShape(ry.ST.ssBox, [.5,2,.1,.02]) .setColor([.5]) .setAttribute(&#39;temperature&#39;, 6000)
C.addFrame(&#39;light2&#39;) .setPosition([-1,0,2]) .setShape(ry.ST.ssBox, [.5,2,.1,.02]) .setColor([.8]) .setAttribute(&#39;temperature&#39;, 6000)
C.view()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nv = render.NvisiiRenderer(600, 400, C.view_focalLength())
nv.addConfig(C)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>nv.setCamera(C)
rgb = nv.render(256)
plt.imshow(rgb)
plt.show()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>del nv
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ext_physx_simulation.html" class="btn btn-neutral float-left" title="Simulation: Low-level stepping interface &amp; gym environments" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ext_rrt.html" class="btn btn-neutral float-right" title="RRT: basic finding example" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Marc Toussaint.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>